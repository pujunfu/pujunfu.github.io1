<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="keywords" content="JUNFU PU, 蒲俊福"> 
<meta name="description" content="JUNFU PU&#39;s home page">
<link rel="stylesheet" href="./configs/style/jemdoc.css" type="text/css">
<style type="text/css">
</style>
<title>JUNFU PU</title>
<meta name="google-site-verification" content="XD95S7QgC1R2IPly-4OXQ6lzzKsavd7ENANS1fqh4DY" />
</head>


<body id="home">

<div id="layout-content" style="margin-top:25px">
<table>
<tbody>
  <tr>
    <td width="100%" valign="top">
      <!-- <img height="50" id="photo" style="padding: 0pt 0pt 0pt 0pt; float: middle; display: inline;" src="./configs/img/engraving.png"> -->
    </td>
  </tr>
  <tr>
    <i><b><font face="Times New Roman" size="7" color="#07689C">Stay active, keep calm, and carry on.</font></b></i>
  </tr>
</tbody>
</table>

<table>
<tbody>
  </tr>
  <tr>
    <td width="39%" valign="top" height="250" align='center'>
      <img height="250" id="photo" style="padding: 0pt 0pt 0pt 50pt; float: left; display: inline;" src="./configs/img/profile.jpg">
    </td>
    
    <td width="60%" valign="top" height="200">
      <!-- <b><font face="Times New Roman" size="6" color="#07689C">JUNFU PU </font><font size="6" face="华文行楷" color="#07689C"> &nbsp 蒲俊福</font><font face="Times New Roman" size="6"></font></b> -->
      <b><font face="Times New Roman" size="6" color="#07689C">JUNFU PU </font> &nbsp <img src="./configs/img/name_4.png" height="50px" style="margin-bottom:-18px"> <img src="./configs/img/name_pjh_5.png" height="65px" style="margin-bottom:-18px"> 
        <font face="Times New Roman" size="6"></font></b>
      <br><br>  
      <p>          
          Researcher at Tencent, Ph.D
      </p>
      <p>
          Dept. Electronic Engineering and Information Science (<a href="http://eeis.ustc.edu.cn/" target="_blank">EEIS</a>)
      </p>
      <p>          
          University of Science and Technology of China (<a href="http://en.ustc.edu.cn/" target="_blank">USTC</a>)
      </p>
      <p>          
          Email: pjh (at) mail.ustc.edu.cn
      </p>
      <p>          
          CV [<a href="./me/cv_en.pdf" target="_blank">English</a>] [<a href="./me/cv_cn.pdf" target="_blank">Chinese</a>]. View on <a href="https://github.com/Jevin754"target="_blank">Github</a>.
      </p>
    </td>
  </tr>
</tbody>
</table>

<br>
<div style="text-align:justify; text-align-last:justify; padding-left: 2.0em; padding-right: 2.0em;">
<a href="#news"><b>News</b></a>
<a href="#openresources"><b>Open-Resources</b></a>
<a href="#publications"><b>Publications</b></a>
<a href="#projects"><b>Projects</b></a>
<a href="#experience"><b>Experience</b></a>
<a href="#teaching"><b>Teaching</b></a>
<a href="#link"><b>Link</b></a>
</div>
<hr style="height:1px; border:none; border-top:1px solid #aaaaaa;">

<!-- ================ Biography ==================-->
<h2>Biography</h2>
<p style="text-align:justify;">
  I am a researcher at Tencent ARC Lab, working on computer vision and multimedia applications.
  I got my PhD degree from <a href="http://ustc.edu.cn" target="_blank">University of Science and Technology of China (USTC)</a>, adviced by <a href="http://staff.ustc.edu.cn/~zhwg/" target="_blank">Prof. Wengang Zhou</a> and <a href="http://staff.ustc.edu.cn/~lihq" target="_blank">Prof. Houqiang Li</a>. 
  Before that, I received the B.E. degree in EE from <a href="https://en.scgy.ustc.edu.cn/" target="_blank">School of the Gifted Young</a>, University of Science and Technology of China (USTC) in 2015. I was a research intern 
  at <a href="http://www.satoh-lab.nii.ac.jp" target="_blank">Satoh Lab</a>, National Institute of Informatics (<a href="http://www.nii.ac.jp/en/" target="_blank">NII</a>) from Aug. 2016 to Nov. 2016. My research project at NII is <strong>video event retrieval</strong> with the supervision of <a href="http://research.nii.ac.jp/~satoh/" target="_blank">Prof. Shin'ichi Satoh</a>.
</p>
<p style="text-align:justify;">
  During my PhD period, my research interests include image processing and computer vision. Specifically, I focus on <strong>sign language recognition and translation</strong>. Besides, I pay attention to sign video generation task as well. 
  <br><br>
  If you are interested in our research on sign language recognition, please visit the homepage of our <a href="./openresources/slr/index.html" target="_blank">Visual Sign Language Research Group </a> to access our Chinese SLR dataset and research papers.
</p>


<!-- ================ News ==================-->
<h2 id="news">News &nbsp <a href="#home" style="color:#666; font-size:15px;">[Top]</a></h2>
<p>
  <li><i><font color="#FF0000">[! Hiring]:</font></i> We are hiring research interns. Contact me if you are interested.</li>
  <li><i>Jul. 2020:</i> One paper is accepted to ACM MM 2020.</li>
  <li><i>Oct. 2019:</i> Our paper is selected as <a href="https://2019.ieeeicip.org/?action=page3&id=3" target="_blank">Best Student Paper Finalists</a> for ICIP 2019.</li>
  <li><i>Feb. 2019:</i> One paper is accepted to CVPR 2019.</li>
  <li><i>Apr. 2018:</i> One paper is accepted to IJCAI-ECAI 2018.</li>
  <li><i>Apr. 2017:</i> One paper is accepted to ICIP 2017.</li>
  <li><i>Oct. 2016:</i> Awarded National Scholarship.</li>
  <li><i>Jun. 2016:</i> Application for Internship Program is accepted by NII.</li>
  <li><i>Jun. 2016:</i> One paper is accepted to PCM 2016.</li>
  <li><i>Mar. 2016:</i> One paper (co-author) is accepted to ICME 2016.</li>
  <li><i>Sep. 2015:</i> One paper is accepted to MMM 2016.</li>
</p>
	

<!-- ================ Open Resources ==================-->
<h2 id="openresources">Open Resources &nbsp<a href="#home" style="color:#666; font-size:15px;">[Top]</a></h2>
<p>
  We have released some resources for research purpose about Sign Language Recognition (SLR). Please refer to the following links:
    <ul>
      <li><a href="./openresources/cslr-dataset-2015/index.html" target="_blank">Isolated SLR500 and Continuous SLR100 for Chinese Sign Language Recognition (CVPR 2019, AAAI 2018)</a>.
      </li>
      <li><a href="http://home.ustc.edu.cn/~zhouh156/dataset/csl-daily/" target="_blank">CSL-Daily: Large-scale Continuous Sign Language Translation (SLT) benchmark (CVPR 2021)</a>.
      </li>
    </ul>
  Source code for project or paper:
    <ul>
      <li>iMaterialist Challenge on Product Recognition (FGVC6, CVPR 2019) [<a href="https://github.com/Jevin754/iMat-Product" target="_blank">Code</a>].</li>
      <li>PyTorch re-implementation of paper "Dilated Convolutional Network with Iterative Optimization for Coutinuous Sign Language Recognition" (IJCAI'18) [<a href="https://github.com/ustc-slr/DilatedSLR" target="_blank">Code</a>].</li>
    </ul>
</p>
 

<!-- ================ Publications ==================-->
<h2 id="publications">Publications &nbsp<a href="#home" style="color:#666; font-size:15px;">[Top]</a></h2>
     
<table border="0" width="100%">
<tbody>
  <tr>
    <th width="25%"></th>
    <th width="75%"></th>
  </tr>




<!--     <tr>
    <td>
    <b><font size="4">Journal papers</font></b><br>
    </td>
  </tr> -->
<!-- ================ New Publication ==================-->
<!--   <tr>
    <td>
      <div align="left">
        <img src="./publications/arXiv2020GlobalLocal/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Global-local Enhancement Network for NMFs-aware Sign Language Recognition</b>
      <br>
      Hezhen Hu, Wengang Zhou, <strong>Junfu Pu</strong>, and Houqiang Li
      <br>
      ACM Transactions on Multimedia Computing Communications and Applications (TOMM), 2020
      <br> -->
<!--       Finished at University of Science and Technology of China (USTC), China
      <br> -->
<!--       [<a href="./publications/arXiv2020GlobalLocal/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/arXiv2020GlobalLocal/bib.txt" target="_blank">BibTex</a>]
      [<a href="https://arxiv.org/abs/2008.10428" target="_blank">arXiv</a>]
    </td>
  </tr>  -->


<!--   <tr>
    <td>
    <br><b><font size="4">Conference papers</font></b><br>
    </td>
  </tr> -->


  <b><font size="4" color="#07689C">Conference & Journal papers</font></b><br>


<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/TMM2023Prio/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Prior-aware Cross Modality Augmentation Learning for Continuous Sign Language Recognition</b>
      <br>
      Hezhen Hu, <strong>Junfu Pu</strong>, Wengang Zhou, and Houqiang Li
      <br>
      IEEE Transactions on Multimedia, 2023
      <br>
      [<a href="./publications/TMM2023Prio/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/TMM2023Prio/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr> 

<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/TMM2022Collaborative/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Collaborative Multilingual Continuous Sign Language Recognition: A Unified Framework</b>
      <br>
      Hezhen Hu*, <strong>Junfu Pu*</strong>, Wengang Zhou, and Houqiang Li <strong>(*equal contribution)</strong>
      <br>
      IEEE Transactions on Multimedia, 2022
      <br>
      [<a href="./publications/TMM2022Collaborative/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/TMM2022Collaborative/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr> 

<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/arXiv2022SSLDanceRep/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Self-Supervised Learning of Music-Dance Representation through Explicit-Implicit Rhythm Synchronization</b>
      <br>
      Jiashuo Yu, <strong>Junfu Pu<sup>#</sup></strong>, Ying Cheng, Rui Feng, and Ying Shan <strong>(<sup>#</sup>corresponding author)</strong>
      <br>
      Technical report: arXiv preprint arXiv:2207.03190, 2022
      <br>
      [<a href="https://arxiv.org/abs/2207.03190" target="_blank">Paper (arXiv)</a>]
      [<a href="./publications/arXiv2022SSLDanceRep/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr> 

<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/arXiv2022MusicDriven/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Music-driven Dance Regeneration with Controllable Key Pose Constraints</b>
      <br>
      <strong>Junfu Pu</strong>, and Ying Shan
      <br>
      Technical report: arXiv preprint arXiv:2207.03682, 2022
      <br>
      [<a href="https://arxiv.org/abs/2207.03682" target="_blank">Paper (arXiv)</a>]
      [<a href="./publications/arXiv2022MusicDriven/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr> 

<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/MM2022PCDance/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>PC-Dance: Posture-controllable Music-driven Dance Synthesis</b>
      <br>
      Jibin Gao, <strong>Junfu Pu</strong>, Honglun Zhang, Ying Shan, and Wei-Shi Zheng
      <br>
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2022
      <br>
   <!--    Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/MM2022PCDance/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/MM2022PCDance/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr> 

<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/CVPR2021Improving/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Improving Sign Language Translation with Monolingual Data by Sign Back-Translation</b>
      <br>
      Hao Zhou, Wengang Zhou, Weizhen Qi, <strong>Junfu Pu</strong>, and Houqiang Li
      <br>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2021
      <br>
   <!--    Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="https://arxiv.org/abs/2105.12397" target="_blank">Paper (arXiv)</a>]
      [<a href="./publications/CVPR2021Improving/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr> 

<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/MM2020Boosting/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Boosting Continuous Sign Language Recognition via Cross Modality Augmentation</b>
      <br>
      <strong>Junfu Pu</strong>, Wengang Zhou, Hezhen Hu, and Houqiang Li
      <br>
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2020
      <br>
<!--       Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/MM2020Boosting/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/MM2020Boosting/bib.txt" target="_blank">BibTex</a>]
      [<a href="https://arxiv.org/abs/2010.05264" target="_blank">arXiv</a>]
      [<a href="./publications/MM2020Boosting/presentation_video.mp4" target="_blank">Presentation</a>]
    </td>
  </tr>   

<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/arXiv2020GlobalLocal/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Global-local Enhancement Network for NMFs-aware Sign Language Recognition</b>
      <br>
      Hezhen Hu, Wengang Zhou, <strong>Junfu Pu</strong>, and Houqiang Li
      <br>
      ACM Transactions on Multimedia Computing Communications and Applications (<strong>TOMM</strong>), 2020
      <br>
<!--       Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/arXiv2020GlobalLocal/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/arXiv2020GlobalLocal/bib.txt" target="_blank">BibTex</a>]
      [<a href="https://arxiv.org/abs/2008.10428" target="_blank">arXiv</a>]
    </td>
  </tr> 

<!-- ================ New Publication ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./publications/CVPR2019Iterative/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Iterative Alignment Network for Continuous Sign Language Recognition</b>
      <br>
      <strong>Junfu Pu</strong>, Wengang Zhou, and Houqiang Li
      <br>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019
      <br>
<!--       Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/CVPR2019Iterative/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/CVPR2019Iterative/bib.txt" target="_blank">BibTex</a>]
      [<a href="./publications/CVPR2019Iterative/poster.pdf" target="_blank">Poster</a>]
      [<a href="./publications/CVPR2019Iterative/main.html" target="_blank">Project</a>]
    </td>
  </tr>

<!-- ================ New Publication ==================-->  
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/ICIP2019Continuous/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Continuous Sign Language Recognition via Reinforcement Learning</b><br>
      Zhihao Zhang, <strong>Junfu Pu</strong>, Liansheng Zhuang, Wengang Zhou, and Houqiang Li<br>
      International Conference on Image Processing (<strong>ICIP, <font color="#FF0000">Best Student Paper Finalists</font></strong>), 2019
      <br>
<!--       Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/ICIP2019Continuous/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/ICIP2019Continuous/bib.txt" target="_blank">BibTex</a>]
      [<a href="https://www.2019.ieeeicip.org/2019.ieeeicip.org/indexf6db.html?action=page3&id=3" target="_blank">Best Student Paper Finalists</a>]
    </td>
  </tr>

<!-- ================ New Publication ==================-->  
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/BigMM2019Deep/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Deep Grammatical Multi-classifier for Continuous Sign Language Recognition</b><br>
      Chengcheng Wei, Wengang Zhou, <strong>Junfu Pu</strong>, and Houqiang Li<br>
      International Conference on Multimedia Big Data (<strong>BigMM</strong>), 2019<br>
  <!--     Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/BigMM2019Deep/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/BigMM2019Deep/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr>

<!-- ================ New Publication ==================-->
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/IJCAI2018Dilated/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Dilated Convolutional Network with Iterative Optimization for Coutinuous Sign Language Recognition</b><br>
      <strong>Junfu Pu</strong>, Wengang Zhou, and Houqiang Li<br>
      International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2018
      <br>
 <!--      Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/IJCAI2018Dilated/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/IJCAI2018Dilated/bib.txt" target="_blank">BibTex</a>]
      [<a href="./publications/IJCAI2018Dilated/slides.pdf" target="_blank">Slides</a>]
      [<a href="https://github.com/ustc-slr/DilatedSLR" target="_blank">Code</a>]
    </td>
  </tr> 
	  
<!-- ================ New Publication ==================-->  
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/MM2017Deep/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Deep Supervised Quantization by Self-Organizing Map</b><br>
      Min Wang, Wengang Zhou, Qi Tian, <strong>Junfu Pu</strong>, and Houqiang Li<br>
      <!-- Finished at University of Science and Technology of China (USTC), China
      <br> -->
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2017<br>
      [<a href="./publications/MM2017Deep/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/MM2017Deep/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr>

<!-- ================ New Publication ==================-->  
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/ICIP2017Energy/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Energy Based Fast Event Retrieval in Video with Temporal Match Kernel</b><br>
      <strong>Junfu Pu</strong>, Yusuke Matsui, Fan Yang, and Shin'ichi Satoh<br>
      International Conference on Image Processing (<strong>ICIP</strong>), 2017<br>
 <!--      Finished at National Institute of Informatics (NII), Tokyo, Japan
      <br> -->
      [<a href="./publications/ICIP2017Energy/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/ICIP2017Energy/bib.txt" target="_blank">BibTex</a>]
      [<a href="./publications/ICIP2017Energy/slides.pdf" target="_blank">Slides</a>]
    </td>
  </tr>

<!-- ================ New Publication ==================-->  
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/PCM2016Sign/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Sign Language Recognition with Multi-modal Features</b><br>
      <strong>Junfu Pu</strong>, Wengang Zhou, and Houqiang Li<br>
      Pacific-Rim Conference on Multimedia (<strong>PCM</strong>), 2016<br>
  <!--     Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/PCM2016Sign/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/PCM2016Sign/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr>

<!-- ================ New Publication ==================-->  
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/MMM2016Sign/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Sign Language Recognition Based on Trajectory Modeling with HMMs</b><br>
      <strong>Junfu Pu</strong>, Wengang Zhou, Jihai Zhang, and Houqiang Li<br>
      International Conference on Multimedia Modelling (<strong>MMM</strong>), 2016<br>
   <!--    Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/MMM2016Sign/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/MMM2016Sign/bib.txt" target="_blank">BibTex</a>]
      [<a href="./publications/MMM2016Sign/poster.pdf" target="_blank">Poster</a>]
    </td>
  </tr>

<!-- ================ New Publication ==================-->  
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./publications/ICME2016Chinese/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>Chinese Sign Language Recognition with Adaptive HMM</b><br>
      Jihai Zhang, Wengang Zhou, Chao Xie, <strong>Junfu Pu</strong>, and Houqiang Li<br>
      International Conference on Multimedia and Expo (<strong>ICME</strong>), 2016<br>
  <!--     Finished at University of Science and Technology of China (USTC), China
      <br> -->
      [<a href="./publications/ICME2016Chinese/paper.pdf" target="_blank">Paper</a>]
      [<a href="./publications/ICME2016Chinese/bib.txt" target="_blank">BibTex</a>]
    </td>
  </tr>
 
</tbody>
</table>

<br><b><font size="4" color="#07689C">Patents</font></b><br>
<ol>
  <li>于家硕, <b>蒲俊福</b>, 单瀛. <b>一种模型训练方法、装置、设备和存储介质</b>. 202210148011.9. 2022.02.17申请.</li>
  <li>李厚强, 周文罡, 胡鹤臻, <b>蒲俊福</b>. <b>基于全局-局部特征增强的孤立词手语识别方法及系统</b>. 202010513333.X. 2020.06.08申请. 2022.07.15授权.</li>
  <li>李厚强, 周文罡, 胡鹤臻, <b>蒲俊福</b>. <b>一种基于跨模态数据增广的连续手语识别方法</b>. 202011060274.1. 2020.09.30申请. 2022.07.15授权.</li> 
  <li>李厚强, 周文罡, <b>蒲俊福</b>, 胡鹤臻. <b>基于多语言协同的连续手语识别系统</b>. 202011060272.2. 2020.09.30申请. 2022.07.15授权.</li>
  <li>李厚强, 周文罡, <b>蒲俊福</b>. <b>手语识别方法及装置</b>. 201910456373.2. 2019.05.29申请. 2021.07.06授权.</li>
  <li>李厚强, <b>蒲俊福</b>, 周文罡. <b>一种手语识别方法及装置</b>. 201810743921.5. 2018.07.09申请.</li>
</ol>

<!-- ================ Projects ==================-->
<h2 id="projects">Projects &nbsp<a href="#home" style="color:#666; font-size:15px;">[Top]</a></h2>
     
<table border="0" width="100%">
<tbody>
<tr>
  <th width="25%"></th>
  <th width="75%"></th>
</tr>
<!-- ================ New Project ==================-->
  <tr>
    <td>
      <div align="left">
        <img src="./projects/deepcraft/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline" align="left">
      <b>DeepCraft: Fall in Love with the World</b>
      <br>
      Yunfeng Wang, Ke Sun, Yue Lv, and <strong>Junfu Pu</strong>
      <br>
      Project for hackathon (HACKxSJTU), 2017.
      <br>
      Finished at SJTU, Shanghai, China
      <br>
      [<a href="https://www.hackx.org/projects/76" target="_blank">Project</a>]
      [<a href="https://github.com/ustc-mcc/HackxSJTU" target="_blank">Code</a>]
      [<a href="https://www.hackx.org/prizes/24" target="_blank">Prize</a>]
      [<a href="./projects/deepcraft/certification.png" target="_blank">Certification</a>]
    </td>
  </tr>   

<!-- ================ New Project ==================-->
<tr>
<tr>
  <tr>
    <td>
      <div align="left">
        <img src="./projects/captchaless/overview.png" alt="" class="img_overview">
      </div>
    </td>
    <td valign="baseline">
      <b>CaptchaLess: A Chrome Extension for Auto-filling Captchas</b><br>
      Yunfeng Wang, Zhihua Huang, and <strong>Junfu Pu</strong><br>
      Final Project for Video Technology Course, Autumn, 2015
      <br>
      Finished at University of Science and Technology of China (USTC), China
      <br>
      [<a href="http://captchaless.github.io/CaptchaLess" target="_blank">Project</a>]
      [<a href="https://github.com/CaptchaLess/CaptchaLess" target="_blank">Code</a>]
      [<a href="https://chrome.google.com/webstore/detail/captchaless/claimmbgfkbkkjdibcghloeibcifnodn" target="_blank">Chrome Extension</a>]
      [<a href="./projects/captchaless/videoTech_rep.pdf" target="_blank">Slides</a>]
    </td>
  </tr> 
     
</tbody>
</table>


<!-- ================ Experience ==================-->
<h2 id="experience">Experience &nbsp<a href="#home" style="color:#666; font-size:15px;">[Top]</a></h2>
  <ul>
    <li class="lists">2020.09 - present, Senior researcher at <a href="http://arc.tencent.com" target="_blank">Applied Research Center (ARC Lab)</a>, Tencent PCG.</li>
    <li class="lists">2015.06 - 2020.07, <a href="http://eeis.ustc.edu.cn" target="_blank">Dept. EEIS</a>, University of Science and Technology of China.</li>
    <li class="lists">2016.08 - 2016.11, Research Intern at National Institute of Informatics (<a href="http://www.nii.ac.jp/en/" target="_blank">NII</a>). Advisor: <a href="http://research.nii.ac.jp/~satoh/" target="_blank">Prof. Satoh</a>. 
    <li class="lists">2011.09 - 2015.06, B.E, School for the Gifted Young (<a href="http://scgy.ustc.edu.cn" target="_blank">SCGY</a>), University of Science and Technology of China. </li>
  </ul>


<!-- ================ Teaching Assistant ==================-->
<h2 id="teaching">Teaching Assistant &nbsp<a href="#home" style="color:#666; font-size:15px;">[Top]</a></h2>
  <ul>
    <li class="lists">Spring 2018, Digital Image Analysis, USTC. [<a href="https://ustc-dia.github.io/1718-2/" target="_blank">Course Homepage</a>]</li>
    <li class="lists">Autumn 2017, Digital Image Analysis, USTC.</li>
  </ul>


<!-- ================ Link ==================-->
<h2 id="link">Link &nbsp<a href="#home" style="color:#666; font-size:15px;">[Top]</a></h2>
  <ul>
    <li><a href="./openresources/slr/index.html" target="_blank">Visual Sign Language Research Group (VSLRG)</a>: SLR dataset and papers of our research group.</li>
    <li><a href="./source/gpu_resources.html" target="_blank">GPU Resources</a>: Check GPU resources.</li>
    <li><a href="http://mccipc.ustc.edu.cn/mediawiki/images/4/47/Torque%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.pdf" target="_blank">GPU Cluster Document</a>: A quick guide for MCC GPU cluster.</li>
    <li><a href="./doc/github.pdf" target="_blank">Github Commands</a>: Useful commands for github.</li>
    <li><a href="./source/cvpr2018_papers.html" target="_blank">CVPR 2018 Papers</a>: CVPR 2018 papers in category.</li>
    <li><a href="http://ustcmcc.github.io/PaperReading" target="_blank">USTC MCC Paper Reading</a>: Documents for paper reading and presentation.</li>
  </ul>

<br>
<hr style="height:1px; border:none; border-top:1px solid #aaaaaa;">
<!-- <IMG SRC="/cgi-bin/Count.cgi?df=pjh.dat" align="left" style="margin-right:20px"></IMG> -->
<div align="right" style="font-family:verdana;color:#800000">&copy; Junfu Pu 2023 &nbsp&nbsp&nbsp&nbsp&nbsp Last updated on Jun 2023</div>

<br>
<div style="width:400px;margin:0 auto">
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=jWKtanh3GLIaA7YarJE404P09JqFOL2zKwXMRyyAEBE'></script>
</div>
	
</div>
</body>
</html>
