<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>CVPR2018</title>
	<link href="../configs/css/mystyle.css" rel="stylesheet">
</head>
<body>
<p align="center"><font size="10"><strong>CVPR 2018 Papers</strong></font></p>

<h1>Image Caption</h1>
	<ol>
		<li><i>GroupCap: Group-Based Image Captioning With Structured Relevance and Diversity Constraints.</i> Fuhai Chen (Xiamen Univ.); Rongrong Ji (); Xiaoshuai Sun (Harbin Inst. of Technology); Yongjian Wu (); Jinsong Su (Xiamen Univ.).</li>

		<li><i>Convolutional Image Captioning.</i> Jyoti Aneja (UIUC); Aditya Deshpande (UIUC); Alexander G. Schwing (). [<a href="https://arxiv.org/abs/1711.09151" target="_blank">PDF</a>]</li>

		<li><i>Learning to Evaluate Image Captioning.</i> Yin Cui (Cornel Tech); Guandao Yang (Cornell Univ.); Andreas Veit (Cornel Tech); Xun Huang (); Serge Belongie (). [<a href="https://vision.cornell.edu/se3/wp-content/uploads/2018/03/1501.pdf" target="_blank">PDF</a>]</li>

		<li><i>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering.</i> Peter Anderson (Australian National Univ.); Xiaodong He (); Chris Buehler (); Damien Teney (Univ. of Adelaide); Mark Johnson (Macquarie Univ.); Stephen Gould (Australian National Univ.); Lei Zhang (Microsoft). [<a href="https://arxiv.org/abs/1707.07998" target="_blank">PDF</a>]</li>

		<li><i>Discriminability Objective for Training Descriptive Captions.</i> Ruotian Luo (Toyota Technological Inst.); Brian Price (Adobe Research); Scott Cohen (Adobe Research); Gregory Shakhnarovich (). [<a href="https://arxiv.org/abs/1803.04376" target="_blank">PDF</a>]</li>

		<li><i>Regularizing RNNs for Caption Generation by Reconstructing the Past With the Present.</i> Xinpeng Chen (Wuhan Univ.); Lin Ma (Tencent AI Lab); Wenhao Jiang (Tencent AI Lab); Jian Yao (); Wei Liu (). [<a href="https://arxiv.org/abs/1803.11439" target="_blank">PDF</a>]</li>

		<li><i>SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text.</i> Alexander Mathews (Australian National Univ.); Lexing Xie (Australian National Univ., Data61); Xuming He (ShanghaiTech Univ.).</li>

		<li><i>	Neural Baby Talk.</i> 	Jiasen Lu (Georgia Inst. of Technology); Jianwei Yang (Georgia Tech); Dhruv Batra (Georgia Tech); Devi Parikh (Georgia Tech). [<a href="https://arxiv.org/abs/1803.09845" target="_blank">PDF</a>][<a href="https://github.com/jiasenlu/NeuralBabyTalk" target="_blank">Code</a>]</li>

	</ol>

<h1>Video Caption</h1>
	<ol>
		<li><i>Video Captioning via Hierarchical Reinforcement Learning.</i> Xin Wang (UC Santa Barbara); Wenhu Chen (); Jiawei Wu (UC Santa Barbara); Yuan-Fang Wang (UC Santa Barbara); William Yang Wang (UC Santa Barbara). [<a href="https://arxiv.org/abs/1711.11135" target="_blank">PDF</a>]</li>

		<li><i>Fine-Grained Video Captioning for Sports Narrative.</i> Huanyu Yu (Shanghai Jiao Tong Univ.); Shuo Cheng (Shanghai Jiao Tong Univ.); Bingbing Ni (); Minsi Wang (Shanghai Jiao Tong Univ.); Jian Zhang (Shanghai Jiao Tong Univ.); Xiaokang Yang ().</li>

		<li><i>Interpretable Video Captioning via Trajectory Structured Localization.</i> Xian Wu (Sysu); Guanbin Li (); Qingxing Cao (Sun Yat-Sen Univ.); Qingge Ji (); Liang Lin ().</li>

		<li><i>Bidirectional Attentive Fusion With Context Gating for Dense Video Captioning.</i> Jingwen Wang (SCUT); Wenhao Jiang (Tencent AI Lab); Lin Ma (Tencent AI Lab); Wei Liu (); Yong Xu (South China Univ. of Technology). [<a href="https://arxiv.org/abs/1804.00100" target="_blank">PDF</a>]</li>

		<li><i>Jointly Localizing and Describing Events for Dense Video Captioning.</i> Yehao Li (Sun Yat-Sen Univ.); Ting Yao (Microsoft Research Asia); Yingwei Pan (Univ. of Science and Technology of China); Hongyang Chao (Sun Yat-Sen Univ.); Tao Mei (Microsoft Research Asia). [<a href="https://arxiv.org/abs/1804.08274" target="_blank">PDF</a>]</li>

		<li><i>M3: Multimodal Memory Modelling for Video Captioning.</i> Junbo Wang (Inst. of Automation, Chinese Academy of Sciences); Wei Wang (); Yan Huang (); Liang Wang (); Tieniu Tan (NLPR). [<a href="https://arxiv.org/abs/1611.05592" target="_blank">PDF</a>]</li>

		<li><i>Reconstruction Network for Video Captioning.</i> Bairui Wang (); Lin Ma (Tencent AI Lab); Wei Zhang (); Wei Liu (). [<a href="https://arxiv.org/abs/1803.11438" target="_blank">PDF</a>]</li>

		<li><i>End-to-End Dense Video Captioning With Masked Transformer.</i> Luowei Zhou (Univ. of Michigan); Yingbo Zhou (Salesforce); Jason J. Corso (); Richard Socher (Meta-Mind); Caiming Xiong (Salesforce). [<a href="https://arxiv.org/abs/1804.00819" target="_blank">PDF</a>]</li>
	</ol>
	

</body>
</html>